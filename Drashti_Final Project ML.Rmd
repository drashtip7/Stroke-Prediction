---
title: "Final Project ML"
author: "Rohit kaushik"
date: "2023-05-05"
output: html_document
---

```{r}
#rm(list=ls())  # clear the environment
stro = read.csv("healthcare-dataset-stroke-data.csv")
View(stro)
summary(stro)
str(stro)
table(stro$stroke)

#stro$stroke=factor(stro$strok)
#levels(stro$stroke)=list(No ="0", Yes="1")
#table(stro$stroke)


```


```{r}
head(stro,10)
tail(stro,10)
names(stro)
dim(stro)
stro = subset (stro, select = -id) # Removed id column.
str(stro)

# Numerical: Age, averageglucose level,bmi.

# Categorical: Gender, evermarried, work Type, Residence type,smoking status, Hypertension, Heart disease, stroke. 
```
For Numeric variable 

Association between stroke and age 

```{r}
boxplot(stro$age ~ stro$stroke, col='orange')
t.test(stro$age ~ stro$stroke, alternative="two.sided", data = stro) # p-value < 2.2e-16
```

Association between stroke and bmi 

```{r}
stro$bmi= as.numeric(stro$bmi)
boxplot(stro$bmi ~ stro$stroke, col='orange') 
t.test(stro$bmi ~ stro$stroke, alternative="two.sided", data = stro) # p-value = 0.000334
```

Association between stroke and avg_glucose_level


```{r}
boxplot(stro$avg_glucose_level ~ stro$stroke, col='orange')
t.test(stro$avg_glucose_level ~ stro$stroke, alternative="two.sided", data = stro) # p-value = 2.401e-11

```

For Categorical variable

Association between stroke and gender

```{r}
x= table(stro$stroke,stro$gender)
x
mosaicplot(x,shade = T)
barplot(x)
chisq.test(x)    # p-value = 0.7895
```
Association between stroke and ever_married

```{r}
x= table(stro$stroke,stro$ever_married)
x
mosaicplot(x,shade = T)
barplot(x)
chisq.test(x)    # p-value = 1.639e-14
```

Association between stroke and work_type

```{r}
x= table(stro$stroke,stro$work_type)
x
mosaicplot(x,shade = T)
barplot(x)
chisq.test(x)    # p-value = 5.398e-10
```

Association between stroke and Residence_type

```{r}
x= table(stro$stroke,stro$Residence_type)
x
mosaicplot(x,shade = T)
barplot(x)
chisq.test(x)    # p-value = 0.2983
```

Association between stroke and smoking_status

```{r}
x= table(stro$stroke,stro$smoking_status)
x
mosaicplot(x,shade = T)
barplot(x)
chisq.test(x)    # p-value = 2.085e-06
```

Association between stroke and hypertension

```{r}
x= table(stro$stroke,stro$hypertension)
x
mosaicplot(x,shade = T)
barplot(x)
chisq.test(x)    # p-value < 2.2e-16
```

Association between stroke and heart_disease

```{r}
x= table(stro$stroke,stro$heart_disease)
x
mosaicplot(x,shade = T)
barplot(x)
chisq.test(x)    # p-value < 2.2e-16
```


```{r}
# Based on p-values we observe gender and residence type are two variables that has no effect. 

stro = subset (stro, select = -Residence_type)
stro = subset (stro, select = -gender)

str(stro)


```


```{r}

#stro$gender= as.factor(stro$gender)
stro$hypertension= as.factor(stro$hypertension)
stro$heart_disease= as.factor(stro$heart_disease)
stro$ever_married= as.factor(stro$ever_married)
stro$work_type= as.factor(stro$work_type)
#stro$Residence_type= as.factor(stro$Residence_type)
stro$smoking_status= as.factor(stro$smoking_status)
stro$stroke = as.factor(stro$stroke)
str(stro)

```




```{r}
set.seed(1)
stro = stro[sample(1:nrow(stro)),]  # Shuffled the rows.

# Train/Test Split

train = stro[1:4088,]
str(train)                 # Split the first 4088 rows for training 
test=stro[4089:5110,]      #Split the remaining rows for testing 
str(test)

#train_new = train[1:3270,]
#val = train[3271: 4088,]
#str(val)

colSums(is.na(stro)) # bmi has 201 missing values.

#sum(stroke$gender=="Other")


summary(train$bmi)
# fill missing values in BMI
train$bmi[which(is.na(train$bmi))] = 28.10
test$bmi[which(is.na(test$bmi))] = 28.10

colSums(is.na(train))
colSums(is.na(test))

# Removing others in gender
#unique(stro$gender)
#droplevel.


```

```{r}
str(train)

train$stroke = as.numeric(train$stroke)-1
train$hypertension= as.numeric(train$hypertension)-1
train$heart_disease= as.numeric(train$heart_disease)-1
train$ever_married= as.numeric(train$ever_married)-1
train$work_type= as.numeric(train$work_type)-1
train$smoking_status= as.numeric(train$smoking_status)-1
str(train)

test$stroke = as.numeric(test$stroke)-1
test$hypertension= as.numeric(test$hypertension)-1
test$heart_disease= as.numeric(test$heart_disease)-1
test$ever_married= as.numeric(test$ever_married)-1
test$work_type= as.numeric(test$work_type)-1
test$smoking_status= as.numeric(test$smoking_status)-1
str(test)

```



```{r}
# Data is imbalance.
# Using SMOTE Technique to balance the data.

library(smotefamily)
library(DMwR2)

smote_output = SMOTE(train[,-9], train$stroke)

balanced_data = smote_output$data
str(balanced_data)
balanced_data$class = as.numeric(balanced_data$class)
hist(balanced_data$class, col ="Orange")

prop.table(table(balanced_data$class))
```



```{r}
str(balanced_data)
str(test)

library(gmodels)
library(crosstable)

#test$stroke=factor(test$stroke)
#balanced_data$class = factor(balanced_data$class)
#levels(test$stroke)=list(No ="0", Yes="1")
#levels(balanced_data$class)=list(No ="0", Yes="1")
#levels(balanced_data$class)=list("0"=No, "1"=Yes)
#class(test$stroke)



logistic_model = glm(class~., data =balanced_data, family = "binomial")
summary(logistic_model)
predictions = predict(logistic_model,test,type = "response")
head(predictions)
#Converting probabilities to actual labels
predicted.labels = factor(ifelse(predictions>0.5, "1","0"))
head(predicted.labels)
CrossTable(test$stroke,predicted.labels)
t= table(test$stroke,predicted.labels)
t

#Accuracy = TP+TN/total
accuracy_logistic = (t[1,1]+t[2,2])/(t[1,1]+t[1,2]+t[2,1]+t[2,2]) 
print(accuracy_logistic)  # 0.7632094


library(ROCR)
#pred = prediction(predictions, balanced_data$class)
#pref = performance(pred,'tpr','fpr')
#plot(pref)
#Precision : TP / (TP+FP)
prec_less = t[1,1]/(t[1,1]+t[2,1])
prec_gre = t[2,2]/(t[2,2]+t[1,2])
prec_less
prec_gre


#Recall : TP / (TP+FN)
reca_less = t[1,1]/(t[1,1]+t[1,2])
reca_gre = t[2,2]/(t[2,2]+t[2,1])
reca_less
reca_gre




logistic_model_1 = glm(class~age+hypertension+heart_disease+work_type+avg_glucose_level, data =balanced_data, family = "binomial")
summary(logistic_model_1)
predictions_1 = predict(logistic_model_1,test,type = "response")
head(predictions_1)
#Converting probabilities to actual labels
predicted.labels_1 = factor(ifelse(predictions_1>0.5, "1","0"))
head(predicted.labels_1)

t1= table(test$stroke,predicted.labels_1)
t1

#Accuracy = TP+TN/total
accuracy_logi = (t1[1,1]+t1[2,2])/(t1[1,1]+t1[1,2]+t1[2,1]+t1[2,2]) 
print(accuracy_logi)  # Better than previous one.  # 0.7651663





```

```{r}
# Decision Tree

balanced_data$class = as.factor(balanced_data$class)
test$stroke = as.factor(test$stroke)

library(C50)
stroke_model30 = C5.0(balanced_data[-9],balanced_data$class,trials = 30)
stroke_model30

stroke_pred30 = predict(stroke_model30,test)

library(gmodels)
t2= table(test$stroke,stroke_pred30)
t2

accuracy_decision = (t2[1,1]+t2[2,2])/(t2[1,1]+t2[1,2]+t2[2,1]+t2[2,2]) 
accuracy_decision  #0.9412916
```


```{r}

set.seed(1)
library(randomForest)
library(caret)

ctrl = trainControl(method = "cv", number = 10)
grid_rf = expand.grid(mtry = c(2, 4, 8, 16))

rf <- randomForest(class ~ ., data = balanced_data)
m_rf = train(class ~ ., data = balanced_data, method = "rf", trControl = ctrl, tuneGrid = grid_rf)

m_rf

rf_predictions_binary = predict(m_rf, test)
table(rf_predictions_binary, test$stroke)
RMSE(rf_predictions_binary,test$stroke) # RMSE is 27133.65

varImp(m_rf)

```

